{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Anomalías en Sistema Solar Fotovoltaico\n",
    "\n",
    "Este notebook implementa tres métodos de detección de anomalías usando datos de:\n",
    "- Datos ambientales (temperatura, velocidad y dirección del viento)\n",
    "- Datos de irradiancia solar\n",
    "- Datos eléctricos de 24 inversores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de librerías y carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo de gráficos\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "environment_data = pd.read_csv('environment_data.csv')\n",
    "irradiance_data = pd.read_csv('irradiance_data.csv')\n",
    "electrical_data = pd.read_csv('electrical_data.csv')\n",
    "\n",
    "# Convertir columnas de fecha a datetime\n",
    "environment_data['measured_on'] = pd.to_datetime(environment_data['measured_on'])\n",
    "irradiance_data['measured_on'] = pd.to_datetime(irradiance_data['measured_on'])\n",
    "electrical_data['measured_on'] = pd.to_datetime(electrical_data['measured_on'])\n",
    "\n",
    "print(f\"Datos ambientales: {environment_data.shape}\")\n",
    "print(f\"Datos de irradiancia: {irradiance_data.shape}\")\n",
    "print(f\"Datos eléctricos: {electrical_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar información básica de cada dataset\n",
    "print(\"=== INFORMACIÓN DE DATOS AMBIENTALES ===\")\n",
    "print(environment_data.info())\n",
    "print(\"\\n=== ESTADÍSTICAS DESCRIPTIVAS ===\")\n",
    "print(environment_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "print(\"Valores nulos en environment_data:\", environment_data.isnull().sum().sum())\n",
    "print(\"Valores nulos en irradiance_data:\", irradiance_data.isnull().sum().sum())\n",
    "print(\"Valores nulos en electrical_data:\", electrical_data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unión y transformación de datos\n",
    "\n",
    "Vamos a unir las tablas usando la columna `measured_on` como clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir environment e irradiance primero\n",
    "merged_data = pd.merge(environment_data, irradiance_data, on='measured_on', how='inner')\n",
    "print(f\"Después de unir environment e irradiance: {merged_data.shape}\")\n",
    "\n",
    "# Luego unir con electrical\n",
    "final_data = pd.merge(merged_data, electrical_data, on='measured_on', how='inner')\n",
    "print(f\"Datos finales combinados: {final_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear características adicionales\n",
    "# Calcular la potencia total AC de todos los inversores\n",
    "ac_power_cols = [col for col in final_data.columns if 'ac_power' in col]\n",
    "final_data['total_ac_power'] = final_data[ac_power_cols].sum(axis=1)\n",
    "\n",
    "# Calcular eficiencia promedio (si tenemos datos DC)\n",
    "dc_power_cols = [col for col in final_data.columns if 'dc_current' in col and 'dc_voltage' in col]\n",
    "\n",
    "# Agregar características temporales\n",
    "final_data['hour'] = final_data['measured_on'].dt.hour\n",
    "final_data['day_of_week'] = final_data['measured_on'].dt.dayofweek\n",
    "final_data['month'] = final_data['measured_on'].dt.month\n",
    "\n",
    "print(\"Características creadas exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementación de detectores de anomalías\n",
    "\n",
    "### 4.1 Método 1: Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar características para el modelo\n",
    "feature_cols = ['ambient_temperature_o_149575', 'wind_speed_o_149576', \n",
    "                'poa_irradiance_o_149574', 'total_ac_power', 'hour']\n",
    "\n",
    "# Preparar datos\n",
    "X = final_data[feature_cols].copy()\n",
    "X = X.fillna(X.mean())  # Imputar valores faltantes\n",
    "\n",
    "# Normalizar datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Implementar Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42, n_estimators=100)\n",
    "final_data['anomaly_isolation'] = iso_forest.fit_predict(X_scaled)\n",
    "final_data['anomaly_score_isolation'] = iso_forest.score_samples(X_scaled)\n",
    "\n",
    "# Contar anomalías\n",
    "n_anomalies_iso = (final_data['anomaly_isolation'] == -1).sum()\n",
    "print(f\"Anomalías detectadas por Isolation Forest: {n_anomalies_iso} ({n_anomalies_iso/len(final_data)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar anomalías de Isolation Forest\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Gráfico 1: Temperatura vs Irradiancia\n",
    "normal = final_data[final_data['anomaly_isolation'] == 1]\n",
    "anomaly = final_data[final_data['anomaly_isolation'] == -1]\n",
    "\n",
    "axes[0, 0].scatter(normal['ambient_temperature_o_149575'], normal['poa_irradiance_o_149574'], \n",
    "                   c='blue', alpha=0.5, label='Normal', s=10)\n",
    "axes[0, 0].scatter(anomaly['ambient_temperature_o_149575'], anomaly['poa_irradiance_o_149574'], \n",
    "                   c='red', alpha=0.8, label='Anomalía', s=20)\n",
    "axes[0, 0].set_xlabel('Temperatura Ambiente (°C)')\n",
    "axes[0, 0].set_ylabel('Irradiancia POA (W/m²)')\n",
    "axes[0, 0].set_title('Isolation Forest: Temperatura vs Irradiancia')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Gráfico 2: Potencia Total vs Hora del día\n",
    "axes[0, 1].scatter(normal['hour'], normal['total_ac_power'], \n",
    "                   c='blue', alpha=0.5, label='Normal', s=10)\n",
    "axes[0, 1].scatter(anomaly['hour'], anomaly['total_ac_power'], \n",
    "                   c='red', alpha=0.8, label='Anomalía', s=20)\n",
    "axes[0, 1].set_xlabel('Hora del día')\n",
    "axes[0, 1].set_ylabel('Potencia AC Total (W)')\n",
    "axes[0, 1].set_title('Isolation Forest: Potencia vs Hora')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Gráfico 3: Distribución de scores de anomalía\n",
    "axes[1, 0].hist(final_data['anomaly_score_isolation'], bins=50, edgecolor='black')\n",
    "axes[1, 0].axvline(x=0, color='red', linestyle='--', label='Umbral')\n",
    "axes[1, 0].set_xlabel('Score de Anomalía')\n",
    "axes[1, 0].set_ylabel('Frecuencia')\n",
    "axes[1, 0].set_title('Distribución de Scores - Isolation Forest')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Gráfico 4: Serie temporal de anomalías\n",
    "sample_data = final_data.iloc[:5000]  # Muestra para visualización\n",
    "axes[1, 1].plot(sample_data['measured_on'], sample_data['total_ac_power'], \n",
    "                'b-', alpha=0.5, linewidth=0.5)\n",
    "anomaly_sample = sample_data[sample_data['anomaly_isolation'] == -1]\n",
    "axes[1, 1].scatter(anomaly_sample['measured_on'], anomaly_sample['total_ac_power'], \n",
    "                   c='red', s=20, label='Anomalías')\n",
    "axes[1, 1].set_xlabel('Fecha')\n",
    "axes[1, 1].set_ylabel('Potencia AC Total (W)')\n",
    "axes[1, 1].set_title('Serie Temporal con Anomalías - Isolation Forest')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Método 2: Mahalanobis Distance con Elliptic Envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar Elliptic Envelope (basado en distancia de Mahalanobis)\n",
    "elliptic = EllipticEnvelope(contamination=0.05, random_state=42)\n",
    "final_data['anomaly_mahalanobis'] = elliptic.fit_predict(X_scaled)\n",
    "final_data['mahalanobis_distance'] = elliptic.mahalanobis(X_scaled)\n",
    "\n",
    "# Contar anomalías\n",
    "n_anomalies_maha = (final_data['anomaly_mahalanobis'] == -1).sum()\n",
    "print(f\"Anomalías detectadas por Mahalanobis: {n_anomalies_maha} ({n_anomalies_maha/len(final_data)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar anomalías de Mahalanobis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Gráfico 1: PCA para visualización 2D\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "normal_maha = X_pca[final_data['anomaly_mahalanobis'] == 1]\n",
    "anomaly_maha = X_pca[final_data['anomaly_mahalanobis'] == -1]\n",
    "\n",
    "axes[0].scatter(normal_maha[:, 0], normal_maha[:, 1], c='blue', alpha=0.5, label='Normal', s=10)\n",
    "axes[0].scatter(anomaly_maha[:, 0], anomaly_maha[:, 1], c='red', alpha=0.8, label='Anomalía', s=20)\n",
    "axes[0].set_xlabel('Primera Componente Principal')\n",
    "axes[0].set_ylabel('Segunda Componente Principal')\n",
    "axes[0].set_title('Mahalanobis: Visualización PCA')\n",
    "axes[0].legend()\n",
    "\n",
    "# Gráfico 2: Distribución de distancias de Mahalanobis\n",
    "axes[1].hist(final_data['mahalanobis_distance'], bins=50, edgecolor='black')\n",
    "threshold = np.percentile(final_data['mahalanobis_distance'], 95)\n",
    "axes[1].axvline(x=threshold, color='red', linestyle='--', label=f'Umbral 95% ({threshold:.2f})')\n",
    "axes[1].set_xlabel('Distancia de Mahalanobis')\n",
    "axes[1].set_ylabel('Frecuencia')\n",
    "axes[1].set_title('Distribución de Distancias de Mahalanobis')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Método 3: Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar Local Outlier Factor\n",
    "# Nota: LOF requiere fit_predict en lugar de fit y predict separados\n",
    "lof = LocalOutlierFactor(contamination=0.05, novelty=False, n_neighbors=20)\n",
    "final_data['anomaly_lof'] = lof.fit_predict(X_scaled)\n",
    "final_data['lof_score'] = lof.negative_outlier_factor_\n",
    "\n",
    "# Contar anomalías\n",
    "n_anomalies_lof = (final_data['anomaly_lof'] == -1).sum()\n",
    "print(f\"Anomalías detectadas por LOF: {n_anomalies_lof} ({n_anomalies_lof/len(final_data)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparación de los tres métodos\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Crear matriz de confusión entre métodos\n",
    "methods = ['Isolation Forest', 'Mahalanobis', 'LOF']\n",
    "confusion_matrix = np.zeros((3, 3))\n",
    "\n",
    "# Calcular coincidencias\n",
    "anomaly_cols = ['anomaly_isolation', 'anomaly_mahalanobis', 'anomaly_lof']\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if i == j:\n",
    "            confusion_matrix[i, j] = (final_data[anomaly_cols[i]] == -1).sum()\n",
    "        else:\n",
    "            confusion_matrix[i, j] = ((final_data[anomaly_cols[i]] == -1) & \n",
    "                                    (final_data[anomaly_cols[j]] == -1)).sum()\n",
    "\n",
    "# Visualizar heatmap\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='g', cmap='Blues', \n",
    "            xticklabels=methods, yticklabels=methods)\n",
    "ax.set_title('Coincidencia de Anomalías entre Métodos')\n",
    "ax.set_xlabel('Método')\n",
    "ax.set_ylabel('Método')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis de consenso y métricas finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear score de consenso\n",
    "final_data['anomaly_count'] = 0\n",
    "for col in anomaly_cols:\n",
    "    final_data['anomaly_count'] += (final_data[col] == -1).astype(int)\n",
    "\n",
    "# Definir niveles de severidad\n",
    "final_data['severity'] = 'Normal'\n",
    "final_data.loc[final_data['anomaly_count'] == 1, 'severity'] = 'Bajo'\n",
    "final_data.loc[final_data['anomaly_count'] == 2, 'severity'] = 'Medio'\n",
    "final_data.loc[final_data['anomaly_count'] == 3, 'severity'] = 'Alto'\n",
    "\n",
    "# Estadísticas de severidad\n",
    "severity_counts = final_data['severity'].value_counts()\n",
    "print(\"\\n=== DISTRIBUCIÓN DE SEVERIDAD ===\")\n",
    "print(severity_counts)\n",
    "print(f\"\\nPorcentaje de datos anómalos (al menos 1 método): {(final_data['anomaly_count'] > 0).sum() / len(final_data) * 100:.2f}%\")\n",
    "print(f\"Porcentaje de consenso total (3 métodos): {(final_data['anomaly_count'] == 3).sum() / len(final_data) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de anomalías por inversor\n",
    "# Verificar si hay inversores con más anomalías\n",
    "inverter_anomalies = {}\n",
    "for i in range(1, 25):  # 24 inversores\n",
    "    inv_col = f'inv_{i:02d}_ac_power_inv_'\n",
    "    inv_cols = [col for col in final_data.columns if inv_col in col]\n",
    "    if inv_cols:\n",
    "        # Calcular anomalías cuando este inversor tiene potencia baja pero otros no\n",
    "        inv_power = final_data[inv_cols[0]]\n",
    "        other_power = final_data['total_ac_power'] - inv_power\n",
    "        \n",
    "        # Detectar cuando este inversor está significativamente por debajo\n",
    "        inv_anomaly = (inv_power < 0.7 * (final_data['total_ac_power'] / 24)) & \\\n",
    "                      (final_data['poa_irradiance_o_149574'] > 200)\n",
    "        \n",
    "        inverter_anomalies[f'Inversor_{i:02d}'] = inv_anomaly.sum()\n",
    "\n",
    "# Mostrar inversores con más problemas\n",
    "inv_df = pd.DataFrame.from_dict(inverter_anomalies, orient='index', columns=['Anomalías'])\n",
    "inv_df = inv_df.sort_values('Anomalías', ascending=False)\n",
    "print(\"\\n=== TOP 10 INVERSORES CON MÁS ANOMALÍAS ===\")\n",
    "print(inv_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exportar resultados y crear informe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con resumen de anomalías\n",
    "anomaly_summary = final_data[final_data['anomaly_count'] > 0][[\n",
    "    'measured_on', 'ambient_temperature_o_149575', 'poa_irradiance_o_149574',\n",
    "    'total_ac_power', 'anomaly_count', 'severity'\n",
    "]].copy()\n",
    "\n",
    "# Agregar información sobre qué métodos detectaron la anomalía\n",
    "anomaly_summary['detected_by'] = ''\n",
    "for idx in anomaly_summary.index:\n",
    "    methods_detected = []\n",
    "    if final_data.loc[idx, 'anomaly_isolation'] == -1:\n",
    "        methods_detected.append('Isolation')\n",
    "    if final_data.loc[idx, 'anomaly_mahalanobis'] == -1:\n",
    "        methods_detected.append('Mahalanobis')\n",
    "    if final_data.loc[idx, 'anomaly_lof'] == -1:\n",
    "        methods_detected.append('LOF')\n",
    "    anomaly_summary.loc[idx, 'detected_by'] = ', '.join(methods_detected)\n",
    "\n",
    "# Guardar resultados\n",
    "anomaly_summary.to_csv('anomaly_report.csv', index=False)\n",
    "print(f\"\\nReporte de anomalías guardado: {len(anomaly_summary)} anomalías detectadas\")\n",
    "\n",
    "# Mostrar muestra del reporte\n",
    "print(\"\\n=== MUESTRA DEL REPORTE DE ANOMALÍAS ===\")\n",
    "print(anomaly_summary.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusiones y Recomendaciones\n",
    "\n",
    "### Resumen de Hallazgos:\n",
    "\n",
    "1. **Isolation Forest** detectó anomalías basándose en el aislamiento de puntos en el espacio de características\n",
    "2. **Mahalanobis Distance** identificó puntos que se desvían significativamente de la distribución normal multivariada\n",
    "3. **Local Outlier Factor** encontró anomalías basándose en la densidad local de los puntos\n",
    "\n",
    "### Métrica de Severidad:\n",
    "- **Normal**: No detectado por ningún método\n",
    "- **Bajo**: Detectado por 1 método (posible falso positivo)\n",
    "- **Medio**: Detectado por 2 métodos (anomalía probable)\n",
    "- **Alto**: Detectado por 3 métodos (anomalía confirmada)\n",
    "\n",
    "### Recomendaciones:\n",
    "1. Investigar las anomalías de severidad \"Alta\" primero\n",
    "2. Revisar los inversores con mayor número de anomalías\n",
    "3. Correlacionar las anomalías con eventos de mantenimiento conocidos\n",
    "4. Implementar alertas en tiempo real basadas en estos modelos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
