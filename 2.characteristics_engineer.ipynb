{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Anomalías con Ingeniería de Características Avanzada\n",
    "\n",
    "Sistema fotovoltaico con 24 inversores + datos ambientales e irradiancia\n",
    "**Métodos**: Isolation Forest, Mahalanobis, LOF + Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from scipy import stats\n",
    "from scipy.signal import savgol_filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga y Unión de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "env_data = pd.read_csv('environment_data.csv')\n",
    "irr_data = pd.read_csv('irradiance_data.csv')\n",
    "elec_data = pd.read_csv('electrical_data.csv')\n",
    "\n",
    "# Convertir fechas\n",
    "for df in [env_data, irr_data, elec_data]:\n",
    "    df['measured_on'] = pd.to_datetime(df['measured_on'])\n",
    "\n",
    "# Unir datos\n",
    "data = env_data.merge(irr_data, on='measured_on', how='inner')\n",
    "data = data.merge(elec_data, on='measured_on', how='inner')\n",
    "data = data.sort_values('measured_on').reset_index(drop=True)\n",
    "\n",
    "print(f\"Datos unidos: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ingeniería de Características Avanzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CARACTERÍSTICAS TEMPORALES ===\n",
    "data['hour'] = data['measured_on'].dt.hour\n",
    "data['day_of_week'] = data['measured_on'].dt.dayofweek\n",
    "data['month'] = data['measured_on'].dt.month\n",
    "data['quarter'] = data['measured_on'].dt.quarter\n",
    "data['is_weekend'] = (data['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "# Características cíclicas\n",
    "data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
    "data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
    "data['day_sin'] = np.sin(2 * np.pi * data['day_of_week'] / 7)\n",
    "data['day_cos'] = np.cos(2 * np.pi * data['day_of_week'] / 7)\n",
    "data['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)\n",
    "data['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)\n",
    "\n",
    "print(\"✓ Características temporales creadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CARACTERÍSTICAS DE POTENCIA ===\n",
    "# Identificar columnas de potencia AC\n",
    "ac_cols = [col for col in data.columns if 'ac_power' in col]\n",
    "data['total_ac_power'] = data[ac_cols].sum(axis=1)\n",
    "data['mean_ac_power'] = data[ac_cols].mean(axis=1)\n",
    "data['std_ac_power'] = data[ac_cols].std(axis=1)\n",
    "data['cv_ac_power'] = data['std_ac_power'] / (data['mean_ac_power'] + 1e-8)\n",
    "\n",
    "# Características de distribución\n",
    "data['min_ac_power'] = data[ac_cols].min(axis=1)\n",
    "data['max_ac_power'] = data[ac_cols].max(axis=1)\n",
    "data['range_ac_power'] = data['max_ac_power'] - data['min_ac_power']\n",
    "data['skew_ac_power'] = data[ac_cols].skew(axis=1)\n",
    "\n",
    "# Percentiles\n",
    "data['q25_ac_power'] = data[ac_cols].quantile(0.25, axis=1)\n",
    "data['q75_ac_power'] = data[ac_cols].quantile(0.75, axis=1)\n",
    "data['iqr_ac_power'] = data['q75_ac_power'] - data['q25_ac_power']\n",
    "\n",
    "print(\"✓ Características de potencia creadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CARACTERÍSTICAS DE EFICIENCIA ===\n",
    "# Eficiencia teórica vs real\n",
    "temp_col = 'ambient_temperature_o_149575'\n",
    "irr_col = 'poa_irradiance_o_149574'\n",
    "wind_col = 'wind_speed_o_149576'\n",
    "\n",
    "# Potencia teórica esperada (modelo simplificado)\n",
    "data['expected_power'] = np.where(\n",
    "    data[irr_col] > 100,\n",
    "    data[irr_col] * 0.8 * (1 - 0.004 * (data[temp_col] - 25)),\n",
    "    0\n",
    ")\n",
    "\n",
    "# Ratios de eficiencia\n",
    "data['efficiency_ratio'] = data['total_ac_power'] / (data['expected_power'] + 1e-8)\n",
    "data['power_per_irradiance'] = data['total_ac_power'] / (data[irr_col] + 1e-8)\n",
    "\n",
    "# Efectos ambientales\n",
    "data['temp_effect'] = 1 - 0.004 * (data[temp_col] - 25)\n",
    "data['wind_cooling'] = np.log1p(data[wind_col])  # Efecto de enfriamiento\n",
    "\n",
    "print(\"✓ Características de eficiencia creadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CARACTERÍSTICAS DE VENTANAS DESLIZANTES ===\n",
    "# Funciones de ventana\n",
    "def rolling_features(series, window=5):\n",
    "    return pd.DataFrame({\n",
    "        f'{series.name}_roll_mean': series.rolling(window, center=True).mean(),\n",
    "        f'{series.name}_roll_std': series.rolling(window, center=True).std(),\n",
    "        f'{series.name}_roll_min': series.rolling(window, center=True).min(),\n",
    "        f'{series.name}_roll_max': series.rolling(window, center=True).max()\n",
    "    })\n",
    "\n",
    "# Aplicar a variables clave\n",
    "key_vars = ['total_ac_power', temp_col, irr_col]\n",
    "for var in key_vars:\n",
    "    roll_feat = rolling_features(data[var])\n",
    "    data = pd.concat([data, roll_feat], axis=1)\n",
    "\n",
    "# Características de diferencias\n",
    "data['power_diff'] = data['total_ac_power'].diff()\n",
    "data['temp_diff'] = data[temp_col].diff()\n",
    "data['irr_diff'] = data[irr_col].diff()\n",
    "\n",
    "# Suavizado\n",
    "if len(data) > 11:\n",
    "    data['power_smooth'] = savgol_filter(data['total_ac_power'], 11, 3)\n",
    "    data['power_residual'] = data['total_ac_power'] - data['power_smooth']\n",
    "\n",
    "print(\"✓ Características de ventanas deslizantes creadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CARACTERÍSTICAS DE INVERSORES INDIVIDUALES ===\n",
    "# Número de inversores activos\n",
    "data['active_inverters'] = (data[ac_cols] > 10).sum(axis=1)\n",
    "\n",
    "# Desviación de cada inversor respecto al promedio\n",
    "for i, col in enumerate(ac_cols[:5]):  # Solo primeros 5 para economizar espacio\n",
    "    data[f'inv_{i+1}_deviation'] = data[col] - data['mean_ac_power']\n",
    "    data[f'inv_{i+1}_zscore'] = stats.zscore(data[col])\n",
    "\n",
    "print(\"✓ Características de inversores individuales creadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CARACTERÍSTICAS DE INTERACCIÓN ===\n",
    "# Interacciones importantes\n",
    "data['temp_irr_interaction'] = data[temp_col] * data[irr_col]\n",
    "data['wind_temp_interaction'] = data[wind_col] * data[temp_col]\n",
    "data['power_efficiency_interaction'] = data['total_ac_power'] * data['efficiency_ratio']\n",
    "\n",
    "# Ratios importantes\n",
    "data['power_to_temp_ratio'] = data['total_ac_power'] / (data[temp_col] + 1e-8)\n",
    "data['irr_to_wind_ratio'] = data[irr_col] / (data[wind_col] + 1e-8)\n",
    "\n",
    "print(\"✓ Características de interacción creadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CARACTERÍSTICAS DE ANOMALÍAS LOCALES ===\n",
    "# Z-scores para detección de outliers\n",
    "numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
    "for col in ['total_ac_power', 'efficiency_ratio', 'cv_ac_power']:\n",
    "    if col in data.columns:\n",
    "        data[f'{col}_zscore'] = np.abs(stats.zscore(data[col]))\n",
    "\n",
    "# Distancia desde percentiles\n",
    "data['power_from_median'] = np.abs(data['total_ac_power'] - data['total_ac_power'].median())\n",
    "data['power_percentile'] = data['total_ac_power'].rank(pct=True)\n",
    "\n",
    "print(\"✓ Características de anomalías locales creadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selección y Preparación de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar características para el modelo\n",
    "feature_cols = [\n",
    "    # Temporales\n",
    "    'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'month_sin', 'month_cos',\n",
    "    'is_weekend',\n",
    "    \n",
    "    # Ambientales\n",
    "    temp_col, irr_col, wind_col,\n",
    "    \n",
    "    # Potencia\n",
    "    'total_ac_power', 'mean_ac_power', 'std_ac_power', 'cv_ac_power',\n",
    "    'range_ac_power', 'skew_ac_power', 'active_inverters',\n",
    "    \n",
    "    # Eficiencia\n",
    "    'efficiency_ratio', 'power_per_irradiance', 'temp_effect',\n",
    "    \n",
    "    # Ventanas deslizantes\n",
    "    'total_ac_power_roll_mean', 'total_ac_power_roll_std',\n",
    "    'power_diff', 'power_residual',\n",
    "    \n",
    "    # Interacciones\n",
    "    'temp_irr_interaction', 'power_efficiency_interaction',\n",
    "    \n",
    "    # Anomalías locales\n",
    "    'total_ac_power_zscore', 'power_from_median', 'power_percentile'\n",
    "]\n",
    "\n",
    "# Filtrar características que existen\n",
    "feature_cols = [col for col in feature_cols if col in data.columns]\n",
    "\n",
    "# Preparar matriz de características\n",
    "X = data[feature_cols].copy()\n",
    "X = X.fillna(X.median())  # Imputar con mediana\n",
    "\n",
    "# Remover infinitos\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"Características seleccionadas: {X.shape[1]}\")\n",
    "print(f\"Datos preparados: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Escalado Robusto y Detección de Anomalías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado robusto (menos sensible a outliers)\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# === MÉTODO 1: ISOLATION FOREST ===\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42, n_estimators=200)\n",
    "data['anomaly_iso'] = iso_forest.fit_predict(X_scaled)\n",
    "data['score_iso'] = iso_forest.score_samples(X_scaled)\n",
    "\n",
    "# === MÉTODO 2: MAHALANOBIS DISTANCE ===\n",
    "elliptic = EllipticEnvelope(contamination=0.05, random_state=42)\n",
    "data['anomaly_maha'] = elliptic.fit_predict(X_scaled)\n",
    "data['score_maha'] = elliptic.mahalanobis(X_scaled)\n",
    "\n",
    "# === MÉTODO 3: LOCAL OUTLIER FACTOR ===\n",
    "lof = LocalOutlierFactor(contamination=0.05, n_neighbors=30)\n",
    "data['anomaly_lof'] = lof.fit_predict(X_scaled)\n",
    "data['score_lof'] = lof.negative_outlier_factor_\n",
    "\n",
    "# Contar anomalías\n",
    "methods = ['anomaly_iso', 'anomaly_maha', 'anomaly_lof']\n",
    "for method in methods:\n",
    "    count = (data[method] == -1).sum()\n",
    "    print(f\"{method}: {count} anomalías ({count/len(data)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis de Consenso y Severidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consenso entre métodos\n",
    "data['consensus_count'] = sum((data[method] == -1).astype(int) for method in methods)\n",
    "\n",
    "# Niveles de severidad\n",
    "data['severity'] = data['consensus_count'].map({\n",
    "    0: 'Normal', 1: 'Bajo', 2: 'Medio', 3: 'Alto'\n",
    "})\n",
    "\n",
    "# Score combinado (promedio normalizado)\n",
    "data['combined_score'] = (\n",
    "    -data['score_iso'] +  # Isolation Forest (más negativo = más anómalo)\n",
    "    data['score_maha'] +  # Mahalanobis (más positivo = más anómalo)\n",
    "    -data['score_lof']    # LOF (más negativo = más anómalo)\n",
    ") / 3\n",
    "\n",
    "print(\"=== DISTRIBUCIÓN DE SEVERIDAD ===\")\n",
    "print(data['severity'].value_counts())\n",
    "print(f\"\\nTotal anomalías: {(data['consensus_count'] > 0).sum()} ({(data['consensus_count'] > 0).sum()/len(data)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualización de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización compacta\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Distribución de severidad\n",
    "severity_counts = data['severity'].value_counts()\n",
    "axes[0, 0].pie(severity_counts.values, labels=severity_counts.index, autopct='%1.1f%%')\n",
    "axes[0, 0].set_title('Distribución de Severidad')\n",
    "\n",
    "# 2. Score combinado vs eficiencia\n",
    "normal = data[data['severity'] == 'Normal']\n",
    "anomaly = data[data['severity'] != 'Normal']\n",
    "axes[0, 1].scatter(normal['efficiency_ratio'], normal['combined_score'], \n",
    "                   alpha=0.5, s=10, label='Normal')\n",
    "axes[0, 1].scatter(anomaly['efficiency_ratio'], anomaly['combined_score'], \n",
    "                   c='red', s=20, label='Anomalía')\n",
    "axes[0, 1].set_xlabel('Ratio de Eficiencia')\n",
    "axes[0, 1].set_ylabel('Score Combinado')\n",
    "axes[0, 1].set_title('Eficiencia vs Score Combinado')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Importancia de características (aproximada)\n",
    "feature_importance = np.abs(X_scaled.std(axis=0))\n",
    "top_features = np.argsort(feature_importance)[-10:]\n",
    "axes[1, 0].barh(range(len(top_features)), feature_importance[top_features])\n",
    "axes[1, 0].set_yticks(range(len(top_features)))\n",
    "axes[1, 0].set_yticklabels([feature_cols[i] for i in top_features])\n",
    "axes[1, 0].set_title('Top 10 Características (por Varianza)')\n",
    "\n",
    "# 4. Serie temporal de anomalías\n",
    "sample_data = data.iloc[:2000]  # Muestra\n",
    "axes[1, 1].plot(sample_data['measured_on'], sample_data['total_ac_power'], \n",
    "                'b-', alpha=0.6, linewidth=0.5)\n",
    "high_anomalies = sample_data[sample_data['severity'] == 'Alto']\n",
    "axes[1, 1].scatter(high_anomalies['measured_on'], high_anomalies['total_ac_power'], \n",
    "                   c='red', s=30, label='Alto Riesgo')\n",
    "axes[1, 1].set_xlabel('Fecha')\n",
    "axes[1, 1].set_ylabel('Potencia Total (W)')\n",
    "axes[1, 1].set_title('Serie Temporal con Anomalías')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análisis de Características Más Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar qué características son más predictivas\n",
    "anomaly_mask = data['consensus_count'] > 0\n",
    "\n",
    "print(\"=== CARACTERÍSTICAS MÁS DISCRIMINATIVAS ===\")\n",
    "for col in ['cv_ac_power', 'efficiency_ratio', 'total_ac_power_zscore', 'power_residual']:\n",
    "    if col in data.columns:\n",
    "        normal_mean = data[~anomaly_mask][col].mean()\n",
    "        anomaly_mean = data[anomaly_mask][col].mean()\n",
    "        diff = abs(anomaly_mean - normal_mean)\n",
    "        print(f\"{col}: Normal={normal_mean:.3f}, Anomalía={anomaly_mean:.3f}, Diff={diff:.3f}\")\n",
    "\n",
    "# Exportar reporte final\n",
    "report = data[data['consensus_count'] > 0][[\n",
    "    'measured_on', 'total_ac_power', 'efficiency_ratio', 'cv_ac_power',\n",
    "    'consensus_count', 'severity', 'combined_score'\n",
    "]].copy()\n",
    "\n",
    "report.to_csv('enhanced_anomaly_report.csv', index=False)\n",
    "print(f\"\\n✓ Reporte mejorado guardado: {len(report)} anomalías\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones del Análisis Mejorado\n",
    "\n",
    "### Mejoras Implementadas:\n",
    "1. **Características Temporales Cíclicas**: Capturan patrones estacionales\n",
    "2. **Métricas de Distribución**: CV, skewness, percentiles de inversores\n",
    "3. **Ventanas Deslizantes**: Detectan cambios temporales\n",
    "4. **Características de Eficiencia**: Comparan performance real vs esperada\n",
    "5. **Interacciones**: Capturan relaciones complejas entre variables\n",
    "6. **Escalado Robusto**: Menos sensible a outliers extremos\n",
    "\n",
    "### Beneficios:\n",
    "- **Mayor Precisión**: Más características = mejor detección\n",
    "- **Menor Ruido**: Escalado robusto reduce falsos positivos\n",
    "- **Interpretabilidad**: Score combinado facilita priorización\n",
    "- **Contexto Operacional**: Características de eficiencia son accionables\n",
    "\n",
    "### Próximos Pasos:\n",
    "1. Validar con datos históricos de fallas conocidas\n",
    "2. Implementar alertas por niveles de severidad\n",
    "3. Crear dashboard interactivo\n",
    "4. Entrenar modelo supervisado con etiquetas de mantenimiento"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
