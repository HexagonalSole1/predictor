{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîã Sistema Integrado de Detecci√≥n de Anomal√≠as en Paneles Solares\n",
    "## Versi√≥n Integrada que usa todos los m√≥dulos desarrollados\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- ‚úÖ Usa `mejoras_ingenieria_caracteristicas.py`\n",
    "- ‚úÖ Usa `mejoras_modelo_anomalias.py`\n",
    "- ‚úÖ Usa `sistema_mejorado_completo.py`\n",
    "- ‚úÖ Mantiene an√°lisis Prophet original\n",
    "- ‚úÖ Sistema de alertas integrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ M√≥dulos propios importados correctamente\n",
      "‚úÖ Prophet importado correctamente\n",
      "\n",
      "üöÄ SISTEMA INTEGRADO DE DETECCI√ìN DE ANOMAL√çAS\n",
      "============================================================\n",
      "‚úì Librer√≠as b√°sicas importadas\n",
      "‚úì M√≥dulos propios: Disponibles\n",
      "‚úì Prophet: Disponible\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELDA 1: Importaciones y configuraci√≥n\n",
    "# ========================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========================================\n",
    "# IMPORTAR NUESTROS M√ìDULOS DESARROLLADOS\n",
    "# ========================================\n",
    "try:\n",
    "    from mejoras_ingenieria_caracteristicas import MejorasIngenieriaCaracteristicas\n",
    "    from mejoras_modelo_anomalias import MejorasModeloAnomalias\n",
    "    from sistema_mejorado_completo import SistemaMejoradoCompleto\n",
    "    print(\"‚úÖ M√≥dulos propios importados correctamente\")\n",
    "    modulos_disponibles = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Error importando m√≥dulos: {e}\")\n",
    "    print(\"Continuando con funcionalidad b√°sica...\")\n",
    "    modulos_disponibles = False\n",
    "\n",
    "# Prophet para an√°lisis predictivo\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    print(\"‚úÖ Prophet importado correctamente\")\n",
    "    prophet_disponible = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Prophet no disponible\")\n",
    "    prophet_disponible = False\n",
    "\n",
    "print(\"\\nüöÄ SISTEMA INTEGRADO DE DETECCI√ìN DE ANOMAL√çAS\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úì Librer√≠as b√°sicas importadas\")\n",
    "print(f\"‚úì M√≥dulos propios: {'Disponibles' if modulos_disponibles else 'No disponibles'}\")\n",
    "print(f\"‚úì Prophet: {'Disponible' if prophet_disponible else 'No disponible'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 2: Funciones de carga de datos\n",
    "# ========================================\n",
    "\n",
    "def find_csv_files(directorio_raiz='.'):\n",
    "    \"\"\"Buscar archivos CSV en el directorio\"\"\"\n",
    "    directorios_con_csv = []\n",
    "    for raiz, directorios, archivos in os.walk(directorio_raiz):\n",
    "        archivos_csv = [archivo for archivo in archivos if archivo.lower().endswith('.csv')]\n",
    "        if archivos_csv:\n",
    "            directorios_con_csv.append(raiz)\n",
    "    return directorios_con_csv\n",
    "\n",
    "def cargar_datasets():\n",
    "    \"\"\"Funci√≥n mejorada para cargar los 3 datasets\"\"\"\n",
    "    print(\"üìä CARGANDO DATASETS...\")\n",
    "    \n",
    "    directorios = find_csv_files()\n",
    "    print(\"Directorios que contienen archivos CSV:\")\n",
    "    for directorio in directorios:\n",
    "        print(f\"- {directorio}\")\n",
    "    \n",
    "    # Buscar los archivos espec√≠ficos\n",
    "    environment_data = None\n",
    "    irradiance_data = None\n",
    "    electrical_data = None\n",
    "    \n",
    "    for directorio in directorios:\n",
    "        # Environment data\n",
    "        ruta_env = os.path.join(directorio, 'environment_data.csv')\n",
    "        if os.path.exists(ruta_env):\n",
    "            environment_data = pd.read_csv(ruta_env)\n",
    "            print(f\"‚úì Cargado: {ruta_env}\")\n",
    "        \n",
    "        # Irradiance data\n",
    "        ruta_irr = os.path.join(directorio, 'irradiance_data.csv')\n",
    "        if os.path.exists(ruta_irr):\n",
    "            irradiance_data = pd.read_csv(ruta_irr)\n",
    "            print(f\"‚úì Cargado: {ruta_irr}\")\n",
    "        \n",
    "        # Electrical data (inversores)\n",
    "        ruta_elec = os.path.join(directorio, 'electrical_data.csv')\n",
    "        if os.path.exists(ruta_elec):\n",
    "            electrical_data = pd.read_csv(ruta_elec)\n",
    "            print(f\"‚úì Cargado: {ruta_elec}\")\n",
    "        \n",
    "        # Tambi√©n buscar chunk_electrical_data.csv como alternativa\n",
    "        ruta_chunk = os.path.join(directorio, 'chunk_electrical_data.csv')\n",
    "        if os.path.exists(ruta_chunk) and electrical_data is None:\n",
    "            electrical_data = pd.read_csv(ruta_chunk)\n",
    "            print(f\"‚úì Cargado: {ruta_chunk}\")\n",
    "    \n",
    "    return environment_data, irradiance_data, electrical_data\n",
    "\n",
    "def seleccionar_variables_inversor_1(electrical_data):\n",
    "    \"\"\"Seleccionar solo las variables del inversor 1 y limpiar nombres\"\"\"\n",
    "    # Seleccionar columnas del inversor 1\n",
    "    columnas_inv1 = ['measured_on']\n",
    "    for col in electrical_data.columns:\n",
    "        if 'inv_01_' in col:\n",
    "            columnas_inv1.append(col)\n",
    "    \n",
    "    df_inv1 = electrical_data[columnas_inv1].copy()\n",
    "    \n",
    "    # Limpiar nombres de columnas (quitar el sufijo _inv_XXXXX)\n",
    "    columnas_limpias = {}\n",
    "    for columna in df_inv1.columns:\n",
    "        if columna == 'measured_on':\n",
    "            columnas_limpias[columna] = columna\n",
    "        elif columna.startswith('inv_01_'):\n",
    "            # Extraer solo la parte del tipo de medici√≥n\n",
    "            partes = columna.split('_inv_')\n",
    "            if len(partes) >= 1:\n",
    "                nuevo_nombre = partes[0].replace('inv_01_', '')\n",
    "                columnas_limpias[columna] = nuevo_nombre\n",
    "    \n",
    "    df_inv1 = df_inv1.rename(columns=columnas_limpias)\n",
    "    return df_inv1\n",
    "\n",
    "def combinar_datasets(environment_data, irradiance_data, electrical_data):\n",
    "    \"\"\"Realizar INNER JOIN de los 3 datasets por measured_on\"\"\"\n",
    "    # Seleccionar variables del inversor 1\n",
    "    df_inv1 = seleccionar_variables_inversor_1(electrical_data)\n",
    "    \n",
    "    print(\"Variables seleccionadas del inversor 1:\")\n",
    "    print(df_inv1.columns.tolist())\n",
    "    \n",
    "    # Convertir measured_on a datetime en todos los datasets\n",
    "    environment_data['measured_on'] = pd.to_datetime(environment_data['measured_on'])\n",
    "    irradiance_data['measured_on'] = pd.to_datetime(irradiance_data['measured_on'])\n",
    "    df_inv1['measured_on'] = pd.to_datetime(df_inv1['measured_on'])\n",
    "    \n",
    "    # Realizar INNER JOIN\n",
    "    print(\"\\nüìä Realizando INNER JOIN...\")\n",
    "    df_combined = environment_data.merge(irradiance_data, on='measured_on', how='inner')\n",
    "    df_final = df_combined.merge(df_inv1, on='measured_on', how='inner')\n",
    "    \n",
    "    print(f\"‚úì Dataset final: {len(df_final)} filas, {len(df_final.columns)} columnas\")\n",
    "    print(\"Columnas finales:\", df_final.columns.tolist())\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä CARGANDO DATASETS...\n",
      "Directorios que contienen archivos CSV:\n",
      "- .\n",
      "‚úì Cargado: ./environment_data.csv\n",
      "‚úì Cargado: ./irradiance_data.csv\n",
      "‚úì Cargado: ./electrical_data.csv\n",
      "Variables seleccionadas del inversor 1:\n",
      "['measured_on', 'dc_current', 'dc_voltage', 'ac_current', 'ac_voltage', 'ac_power']\n",
      "\n",
      "üìä Realizando INNER JOIN...\n",
      "‚úì Dataset final: 175566 filas, 10 columnas\n",
      "Columnas finales: ['measured_on', 'ambient_temperature_o_149575', 'wind_speed_o_149576', 'wind_direction_o_149577', 'poa_irradiance_o_149574', 'dc_current', 'dc_voltage', 'ac_current', 'ac_voltage', 'ac_power']\n",
      "\n",
      "‚úÖ Datos combinados exitosamente: (175566, 10)\n",
      "\n",
      "üìä INFORMACI√ìN DEL DATASET COMBINADO:\n",
      "   - Registros: 175,566\n",
      "   - Columnas: 10\n",
      "   - Per√≠odo: 2017-12-01 00:15:00 a 2023-10-31 23:45:00\n",
      "   - Valores nulos: 143\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELDA 3: Cargar datos\n",
    "# ========================================\n",
    "\n",
    "# Cargar los datasets\n",
    "environment_data, irradiance_data, electrical_data = cargar_datasets()\n",
    "\n",
    "if any(data is None for data in [environment_data, irradiance_data, electrical_data]):\n",
    "    print(\"‚ùå Error: No se pudieron cargar todos los datasets necesarios\")\n",
    "    print(\"Archivos requeridos:\")\n",
    "    print(\"- environment_data.csv\")\n",
    "    print(\"- irradiance_data.csv\")\n",
    "    print(\"- electrical_data.csv (o chunk_electrical_data.csv)\")\n",
    "else:\n",
    "    # Combinar datasets\n",
    "    df_combined = combinar_datasets(environment_data, irradiance_data, electrical_data)\n",
    "    print(f\"\\n‚úÖ Datos combinados exitosamente: {df_combined.shape}\")\n",
    "    \n",
    "    # Mostrar informaci√≥n b√°sica\n",
    "    print(f\"\\nüìä INFORMACI√ìN DEL DATASET COMBINADO:\")\n",
    "    print(f\"   - Registros: {len(df_combined):,}\")\n",
    "    print(f\"   - Columnas: {len(df_combined.columns)}\")\n",
    "    print(f\"   - Per√≠odo: {df_combined['measured_on'].min()} a {df_combined['measured_on'].max()}\")\n",
    "    print(f\"   - Valores nulos: {df_combined.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß APLICANDO INGENIER√çA DE CARACTER√çSTICAS CON M√ìDULO INTEGRADO\n",
      "======================================================================\n",
      "Aplicando mejoras de ingenier√≠a de caracter√≠sticas...\n",
      "üöÄ APLICANDO TODAS LAS MEJORAS DE INGENIER√çA DE CARACTER√çSTICAS\n",
      "===========================================================================\n",
      "üïê CREANDO CARACTER√çSTICAS TEMPORALES AVANZADAS\n",
      "============================================================\n",
      "‚úì Caracter√≠sticas temporales creadas: 14 nuevas variables\n",
      "\n",
      "‚ö° CREANDO CARACTER√çSTICAS F√çSICAS MEJORADAS\n",
      "=======================================================\n",
      "‚ö†Ô∏è Error en ingenier√≠a de caracter√≠sticas: 'total_ac_power'\n",
      "Continuando con caracter√≠sticas b√°sicas...\n",
      "Creando caracter√≠sticas b√°sicas...\n",
      "‚úì Caracter√≠sticas b√°sicas creadas: 14 columnas total\n",
      "\n",
      "üìä RESUMEN DE CARACTER√çSTICAS:\n",
      "   - Dataset shape: (175566, 14)\n",
      "   - Tipo de caracter√≠sticas: B√°sicas\n",
      "   - Registros v√°lidos: 175566\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELDA 4: INGENIER√çA DE CARACTER√çSTICAS USANDO M√ìDULO\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nüîß APLICANDO INGENIER√çA DE CARACTER√çSTICAS CON M√ìDULO INTEGRADO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Preparar datos con √≠ndice temporal\n",
    "df_for_features = df_combined.copy()\n",
    "df_for_features = df_for_features.set_index('measured_on')\n",
    "\n",
    "if modulos_disponibles:\n",
    "    # Usar el m√≥dulo de mejoras de caracter√≠sticas\n",
    "    try:\n",
    "        # Inicializar el mejorador de caracter√≠sticas\n",
    "        mejorador_caracteristicas = MejorasIngenieriaCaracteristicas()\n",
    "        \n",
    "        # Aplicar todas las mejoras de caracter√≠sticas\n",
    "        print(\"Aplicando mejoras de ingenier√≠a de caracter√≠sticas...\")\n",
    "        df_con_caracteristicas = mejorador_caracteristicas.aplicar_todas_mejoras(df_for_features)\n",
    "        \n",
    "        print(f\"‚úÖ Ingenier√≠a de caracter√≠sticas completada exitosamente\")\n",
    "        print(f\"   - Caracter√≠sticas originales: {len(df_for_features.columns)}\")\n",
    "        print(f\"   - Caracter√≠sticas finales: {len(df_con_caracteristicas.columns)}\")\n",
    "        print(f\"   - Nuevas caracter√≠sticas creadas: {len(df_con_caracteristicas.columns) - len(df_for_features.columns)}\")\n",
    "        \n",
    "        caracteristicas_creadas = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error en ingenier√≠a de caracter√≠sticas: {e}\")\n",
    "        print(\"Continuando con caracter√≠sticas b√°sicas...\")\n",
    "        df_con_caracteristicas = df_for_features.copy()\n",
    "        caracteristicas_creadas = False\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è M√≥dulo de caracter√≠sticas no disponible, usando caracter√≠sticas b√°sicas\")\n",
    "    df_con_caracteristicas = df_for_features.copy()\n",
    "    caracteristicas_creadas = False\n",
    "\n",
    "# Crear algunas caracter√≠sticas b√°sicas si el m√≥dulo no est√° disponible\n",
    "if not caracteristicas_creadas:\n",
    "    print(\"Creando caracter√≠sticas b√°sicas...\")\n",
    "    \n",
    "    # Caracter√≠sticas temporales b√°sicas\n",
    "    df_con_caracteristicas['hour'] = df_con_caracteristicas.index.hour\n",
    "    df_con_caracteristicas['day_of_week'] = df_con_caracteristicas.index.dayofweek\n",
    "    df_con_caracteristicas['month'] = df_con_caracteristicas.index.month\n",
    "    \n",
    "    # Potencia total AC si hay m√∫ltiples columnas\n",
    "    ac_power_cols = [col for col in df_con_caracteristicas.columns if 'ac_power' in col]\n",
    "    if len(ac_power_cols) > 1:\n",
    "        df_con_caracteristicas['total_ac_power'] = df_con_caracteristicas[ac_power_cols].sum(axis=1)\n",
    "    elif len(ac_power_cols) == 1:\n",
    "        df_con_caracteristicas['total_ac_power'] = df_con_caracteristicas[ac_power_cols[0]]\n",
    "    \n",
    "    # Eficiencia b√°sica\n",
    "    if 'total_ac_power' in df_con_caracteristicas.columns and 'poa_irradiance_o_149574' in df_con_caracteristicas.columns:\n",
    "        df_con_caracteristicas['eficiencia_basica'] = df_con_caracteristicas['total_ac_power'] / (df_con_caracteristicas['poa_irradiance_o_149574'] + 1e-6)\n",
    "    \n",
    "    print(f\"‚úì Caracter√≠sticas b√°sicas creadas: {len(df_con_caracteristicas.columns)} columnas total\")\n",
    "\n",
    "print(f\"\\nüìä RESUMEN DE CARACTER√çSTICAS:\")\n",
    "print(f\"   - Dataset shape: {df_con_caracteristicas.shape}\")\n",
    "print(f\"   - Tipo de caracter√≠sticas: {'Avanzadas (95+)' if caracteristicas_creadas else 'B√°sicas'}\")\n",
    "print(f\"   - Registros v√°lidos: {len(df_con_caracteristicas)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè∑Ô∏è CREANDO ETIQUETAS DE ANOMAL√çA\n",
      "=============================================\n",
      "   - Usando 14 caracter√≠sticas num√©ricas\n",
      "   - Datos limpios: 175566 registros\n",
      "   - Aplicando Isolation Forest...\n",
      "   - Aplicando Local Outlier Factor...\n",
      "   - Isolation Forest detect√≥: 8779 anomal√≠as\n",
      "   - LOF detect√≥: 7461 anomal√≠as\n",
      "   - Consenso final: 15649 anomal√≠as\n",
      "\n",
      "‚úÖ Etiquetas de anomal√≠a creadas exitosamente\n",
      "   - Anomal√≠as detectadas: 15649 (8.91%)\n",
      "   - Datos normales: 159917 (91.09%)\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELDA 5: CREAR ETIQUETAS DE ANOMAL√çA\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nüè∑Ô∏è CREANDO ETIQUETAS DE ANOMAL√çA\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "def crear_etiquetas_anomalia_basicas(df):\n",
    "    \"\"\"Crear etiquetas de anomal√≠a usando m√©todos b√°sicos\"\"\"\n",
    "    # Usar m√©todos simples para crear etiquetas\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    from sklearn.neighbors import LocalOutlierFactor\n",
    "    \n",
    "    # Seleccionar caracter√≠sticas num√©ricas\n",
    "    numeric_data = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Limpiar datos\n",
    "    numeric_data = numeric_data.fillna(numeric_data.median())\n",
    "    numeric_data = numeric_data.replace([np.inf, -np.inf], np.nan)\n",
    "    numeric_data = numeric_data.fillna(numeric_data.median())\n",
    "    \n",
    "    print(f\"   - Usando {len(numeric_data.columns)} caracter√≠sticas num√©ricas\")\n",
    "    print(f\"   - Datos limpios: {len(numeric_data)} registros\")\n",
    "    \n",
    "    # Normalizar\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(numeric_data)\n",
    "    \n",
    "    # Isolation Forest\n",
    "    print(\"   - Aplicando Isolation Forest...\")\n",
    "    iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "    anomalias_iso = iso_forest.fit_predict(X_scaled)\n",
    "    \n",
    "    # LOF\n",
    "    print(\"   - Aplicando Local Outlier Factor...\")\n",
    "    lof = LocalOutlierFactor(contamination=0.05, novelty=True)\n",
    "    lof.fit(X_scaled)\n",
    "    anomalias_lof = lof.predict(X_scaled)\n",
    "    \n",
    "    # Combinar (anomal√≠a si al menos uno la detecta)\n",
    "    etiquetas_finales = ((anomalias_iso == -1) | (anomalias_lof == -1)).astype(int)\n",
    "    \n",
    "    print(f\"   - Isolation Forest detect√≥: {(anomalias_iso == -1).sum()} anomal√≠as\")\n",
    "    print(f\"   - LOF detect√≥: {(anomalias_lof == -1).sum()} anomal√≠as\")\n",
    "    print(f\"   - Consenso final: {etiquetas_finales.sum()} anomal√≠as\")\n",
    "    \n",
    "    return etiquetas_finales\n",
    "\n",
    "# Crear etiquetas\n",
    "try:\n",
    "    etiquetas_anomalia = crear_etiquetas_anomalia_basicas(df_con_caracteristicas)\n",
    "    df_con_caracteristicas['anomalia'] = etiquetas_anomalia\n",
    "    \n",
    "    print(f\"\\n‚úÖ Etiquetas de anomal√≠a creadas exitosamente\")\n",
    "    print(f\"   - Anomal√≠as detectadas: {etiquetas_anomalia.sum()} ({etiquetas_anomalia.sum()/len(etiquetas_anomalia)*100:.2f}%)\")\n",
    "    print(f\"   - Datos normales: {(etiquetas_anomalia == 0).sum()} ({(etiquetas_anomalia == 0).sum()/len(etiquetas_anomalia)*100:.2f}%)\")\n",
    "    \n",
    "    etiquetas_creadas = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error creando etiquetas: {e}\")\n",
    "    # Crear etiquetas dummy si hay error\n",
    "    df_con_caracteristicas['anomalia'] = 0\n",
    "    etiquetas_creadas = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ APLICANDO MEJORAS DE MODELOS ML CON M√ìDULO INTEGRADO\n",
      "=================================================================\n",
      "‚úì Datos preparados para ML:\n",
      "   - Caracter√≠sticas: 14\n",
      "   - Muestras: 175566\n",
      "   - Anomal√≠as: 15649\n",
      "Aplicando mejoras de modelo (supervisado)...\n",
      "üöÄ APLICANDO TODAS LAS MEJORAS DEL MODELO\n",
      "=======================================================\n",
      "\n",
      "üìè CREANDO ESCALADORES ROBUSTOS\n",
      "========================================\n",
      "\n",
      "üß† APLICANDO ESCALADO INTELIGENTE (auto)\n",
      "==================================================\n",
      "‚úì Escalado aplicado: robust\n",
      "‚úì Forma de datos: (175566, 14)\n",
      "ü§ñ CREANDO ENSEMBLE AVANZADO DE MODELOS\n",
      "=======================================================\n",
      "\n",
      "üîß OPTIMIZANDO HIPERPAR√ÅMETROS PARA RANDOM_FOREST\n",
      "============================================================\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELDA 6: APLICAR MEJORAS DE MODELO ML USANDO M√ìDULO\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nü§ñ APLICANDO MEJORAS DE MODELOS ML CON M√ìDULO INTEGRADO\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "if modulos_disponibles and etiquetas_creadas:\n",
    "    # Preparar datos para ML\n",
    "    X_features = df_con_caracteristicas.select_dtypes(include=[np.number]).drop('anomalia', axis=1, errors='ignore')\n",
    "    y_labels = df_con_caracteristicas['anomalia']\n",
    "    \n",
    "    # Limpiar datos finales\n",
    "    X_features = X_features.fillna(X_features.median())\n",
    "    X_features = X_features.replace([np.inf, -np.inf], np.nan)\n",
    "    X_features = X_features.fillna(X_features.median())\n",
    "    \n",
    "    print(f\"‚úì Datos preparados para ML:\")\n",
    "    print(f\"   - Caracter√≠sticas: {X_features.shape[1]}\")\n",
    "    print(f\"   - Muestras: {X_features.shape[0]}\")\n",
    "    print(f\"   - Anomal√≠as: {y_labels.sum()}\")\n",
    "    \n",
    "    # Verificar que tenemos suficientes anomal√≠as para entrenamiento\n",
    "    if y_labels.sum() < 5:\n",
    "        print(\"‚ö†Ô∏è Muy pocas anomal√≠as para entrenamiento supervisado\")\n",
    "        print(\"Usando m√©todo no supervisado...\")\n",
    "        metodo_ml = 'no_supervisado'\n",
    "    else:\n",
    "        metodo_ml = 'supervisado'\n",
    "    \n",
    "    try:\n",
    "        # Inicializar mejorador de modelos\n",
    "        mejorador_modelo = MejorasModeloAnomalias()\n",
    "        \n",
    "        # Aplicar todas las mejoras de modelo\n",
    "        print(f\"Aplicando mejoras de modelo ({metodo_ml})...\")\n",
    "        resultados_ml = mejorador_modelo.aplicar_todas_mejoras(\n",
    "            X_features, \n",
    "            y_labels if metodo_ml == 'supervisado' else None, \n",
    "            metodo=metodo_ml\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Mejoras de modelo aplicadas exitosamente\")\n",
    "        print(f\"   - Modelos entrenados: {len(resultados_ml['modelos'])}\")\n",
    "        print(f\"   - M√©todo usado: {metodo_ml}\")\n",
    "        \n",
    "        if 'sistema_multinivel' in resultados_ml:\n",
    "            print(f\"   - Sistema multinivel: {len(resultados_ml['sistema_multinivel'])} niveles\")\n",
    "        \n",
    "        # Evaluar modelos si es supervisado\n",
    "        if metodo_ml == 'supervisado':\n",
    "            from sklearn.model_selection import train_test_split\n",
    "            \n",
    "            try:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X_features, y_labels, test_size=0.2, random_state=42, stratify=y_labels\n",
    "                )\n",
    "                \n",
    "                # Evaluar cada modelo\n",
    "                resultados_evaluacion = {}\n",
    "                print(\"\\nüìä Evaluando modelos:\")\n",
    "                \n",
    "                for nombre, modelo in resultados_ml['modelos'].items():\n",
    "                    try:\n",
    "                        modelo.fit(X_train, y_train)\n",
    "                        resultado_eval = mejorador_modelo.evaluar_modelo_avanzado(\n",
    "                            modelo, X_test, y_test, nombre\n",
    "                        )\n",
    "                        resultados_evaluacion[nombre] = resultado_eval\n",
    "                        print(f\"   - {nombre}: F1-Score = {resultado_eval['f1']:.3f}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"   - Error evaluando {nombre}: {e}\")\n",
    "                \n",
    "                # Encontrar mejor modelo\n",
    "                if resultados_evaluacion:\n",
    "                    mejor_modelo = max(resultados_evaluacion.keys(), \n",
    "                                      key=lambda x: resultados_evaluacion[x]['f1'])\n",
    "                    print(f\"\\nüèÜ Mejor modelo: {mejor_modelo} (F1: {resultados_evaluacion[mejor_modelo]['f1']:.3f})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error en evaluaci√≥n: {e}\")\n",
    "                resultados_evaluacion = None\n",
    "        else:\n",
    "            resultados_evaluacion = None\n",
    "        \n",
    "        ml_exitoso = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error en mejoras de modelo: {e}\")\n",
    "        print(\"Continuando con an√°lisis b√°sico...\")\n",
    "        resultados_ml = None\n",
    "        resultados_evaluacion = None\n",
    "        ml_exitoso = False\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è M√≥dulos ML no disponibles o etiquetas no creadas\")\n",
    "    print(\"Saltando an√°lisis ML avanzado...\")\n",
    "    resultados_ml = None\n",
    "    resultados_evaluacion = None\n",
    "    ml_exitoso = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 7: AN√ÅLISIS PROPHET (PRESERVADO DEL ORIGINAL)\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nüîÆ AN√ÅLISIS PREDICTIVO CON PROPHET\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "def analisis_prophet_integrado(df_original):\n",
    "    \"\"\"An√°lisis Prophet integrado con el sistema\"\"\"\n",
    "    \n",
    "    if not prophet_disponible:\n",
    "        print(\"‚ö†Ô∏è Prophet no est√° disponible\")\n",
    "        return None\n",
    "    \n",
    "    # Preparar datos para Prophet\n",
    "    df_prophet = df_original.copy()\n",
    "    \n",
    "    # Buscar columna de potencia AC\n",
    "    power_cols = [col for col in df_prophet.columns if 'ac_power' in col.lower()]\n",
    "    if not power_cols:\n",
    "        # Crear potencia total si no existe\n",
    "        ac_cols = [col for col in df_prophet.columns if 'ac_power' in col]\n",
    "        if ac_cols:\n",
    "            df_prophet['total_ac_power'] = df_prophet[ac_cols].sum(axis=1)\n",
    "            power_col = 'total_ac_power'\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No se encontraron columnas de potencia AC\")\n",
    "            return None\n",
    "    else:\n",
    "        power_col = power_cols[0]\n",
    "    \n",
    "    print(f\"Usando columna de potencia: {power_col}\")\n",
    "    \n",
    "    # Preparar datos\n",
    "    df_prophet = df_prophet[['measured_on', power_col]].dropna()\n",
    "    df_prophet = df_prophet[df_prophet[power_col] > 0]\n",
    "    \n",
    "    print(f\"Datos iniciales para Prophet: {len(df_prophet)} registros\")\n",
    "    \n",
    "    # Filtro IQR para limpiar outliers extremos\n",
    "    Q1 = df_prophet[power_col].quantile(0.25)\n",
    "    Q3 = df_prophet[power_col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df_prophet = df_prophet[\n",
    "        (df_prophet[power_col] >= Q1 - 1.0 * IQR) & \n",
    "        (df_prophet[power_col] <= Q3 + 1.0 * IQR)\n",
    "    ]\n",
    "    \n",
    "    # Filtro por percentiles extremos\n",
    "    lower = df_prophet[power_col].quantile(0.02)\n",
    "    upper = df_prophet[power_col].quantile(0.98)\n",
    "    df_prophet = df_prophet[\n",
    "        (df_prophet[power_col] >= lower) & \n",
    "        (df_prophet[power_col] <= upper)\n",
    "    ]\n",
    "    \n",
    "    print(f\"Datos despu√©s de filtros: {len(df_prophet)} registros\")\n",
    "    \n",
    "    # Resampleo diario\n",
    "    df_hourly = df_prophet.set_index('measured_on').resample('D').mean().dropna().reset_index()\n",
    "    \n",
    "    # Preparar para Prophet\n",
    "    df_prophet_final = df_hourly.rename(columns={'measured_on': 'ds', power_col: 'y'})[['ds', 'y']]\n",
    "    df_prophet_final = df_prophet_final[df_prophet_final['y'] > 5]\n",
    "    \n",
    "    if len(df_prophet_final) < 30:\n",
    "        print(f\"‚ö†Ô∏è Datos insuficientes para Prophet: {len(df_prophet_final)} < 30\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úì Datos finales para Prophet: {len(df_prophet_final)} registros\")\n",
    "    \n",
    "    try:\n",
    "        # Entrenar modelo Prophet\n",
    "        print(\"Entrenando modelo Prophet...\")\n",
    "        model = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=True,\n",
    "            daily_seasonality=False,\n",
    "            seasonality_mode='additive'\n",
    "        )\n",
    "        model.fit(df_prophet_final)\n",
    "        \n",
    "        # Predicciones futuras\n",
    "        print(\"Generando predicciones futuras...\")\n",
    "        future = model.make_future_dataframe(periods=360)\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "        # Evitar valores negativos\n",
    "        forecast['yhat'] = forecast['yhat'].clip(lower=0)\n",
    "        forecast['yhat_lower'] = forecast['yhat_lower'].clip(lower=0)\n",
    "        forecast['yhat_upper'] = forecast['yhat_upper'].clip(lower=0)\n",
    "        \n",
    "        # Evaluaci√≥n del modelo\n",
    "        y_true = df_prophet_final['y'].reset_index(drop=True)\n",
    "        y_pred = forecast['yhat'][:len(y_true)].reset_index(drop=True)\n",
    "        \n",
    "        from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        \n",
    "        # SMAPE\n",
    "        def smape(y_true, y_pred):\n",
    "            return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "        \n",
    "        smape_val = smape(y_true, y_pred)\n",
    "        \n",
    "        print(f\"‚úÖ Modelo Prophet entrenado exitosamente:\")\n",
    "        print(f\"   - MAE: {mae:.2f}\")\n",
    "        print(f\"   - RMSE: {rmse:.2f}\")\n",
    "        print(f\"   - SMAPE: {smape_val:.2f}%\")\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'forecast': forecast,\n",
    "            'data_used': df_prophet_final,\n",
    "            'metrics': {\n",
    "                'mae': mae,\n",
    "                'rmse': rmse,\n",
    "                'smape': smape_val\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error en Prophet: {e}\")\n",
    "        return None\n",
    "\n",
    "# Ejecutar an√°lisis Prophet\n",
    "resultados_prophet = analisis_prophet_integrado(df_combined)\n",
    "\n",
    "if resultados_prophet:\n",
    "    print(f\"\\n‚úÖ An√°lisis Prophet completado exitosamente\")\n",
    "    print(f\"   - Predicciones generadas: {len(resultados_prophet['forecast'])}\")\n",
    "    print(f\"   - Datos usados: {len(resultados_prophet['data_used'])}\")\n",
    "    print(f\"   - SMAPE: {resultados_prophet['metrics']['smape']:.2f}%\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è No se pudo completar el an√°lisis Prophet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 8: VISUALIZACIONES INTEGRADAS\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nüìä GENERANDO VISUALIZACIONES INTEGRADAS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def visualizaciones_integradas(df_anomalias, resultados_ml, resultados_prophet, resultados_eval):\n",
    "    \"\"\"Crear visualizaciones que integran todos los resultados\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "    fig.suptitle('üîã Dashboard Integrado - Sistema de Detecci√≥n de Anomal√≠as', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Prophet - Predicciones (si disponible)\n",
    "    ax1 = axes[0, 0]\n",
    "    if resultados_prophet:\n",
    "        prophet_data = resultados_prophet['data_used']\n",
    "        forecast = resultados_prophet['forecast']\n",
    "        \n",
    "        ax1.plot(prophet_data['ds'], prophet_data['y'], 'o', markersize=3, label='Datos Reales', alpha=0.7, color='blue')\n",
    "        ax1.plot(forecast['ds'], forecast['yhat'], '-', color='red', label='Predicci√≥n Prophet', linewidth=2)\n",
    "        ax1.fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'], \n",
    "                        color='red', alpha=0.2, label='Intervalo de Confianza')\n",
    "        ax1.set_title('üîÆ Predicciones Prophet - Producci√≥n Solar')\n",
    "        ax1.set_xlabel('Fecha')\n",
    "        ax1.set_ylabel('Potencia AC')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, 'Prophet no disponible', transform=ax1.transAxes, \n",
    "                ha='center', va='center', fontsize=14)\n",
    "        ax1.set_title('üîÆ Predicciones Prophet - No Disponible')\n",
    "    \n",
    "    # 2. Rendimiento de modelos ML (si disponible)\n",
    "    ax2 = axes[0, 1]\n",
    "    if resultados_eval and len(resultados_eval) > 0:\n",
    "        modelos = list(resultados_eval.keys())\n",
    "        f1_scores = [resultados_eval[modelo]['f1'] for modelo in modelos]\n",
    "        \n",
    "        colors = ['red', 'orange', 'green', 'blue', 'purple'][:len(modelos)]\n",
    "        bars = ax2.bar(modelos, f1_scores, color=colors)\n",
    "        ax2.set_title('ü§ñ Rendimiento de Modelos ML (F1-Score)')\n",
    "        ax2.set_ylabel('F1-Score')\n",
    "        ax2.set_ylim(0, 1)\n",
    "        \n",
    "        # Agregar valores en las barras\n",
    "        for bar, score in zip(bars, f1_scores):\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{score:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'Modelos ML no evaluados', transform=ax2.transAxes, \n",
    "                ha='center', va='center', fontsize=14)\n",
    "        ax2.set_title('ü§ñ Modelos ML - No Disponible')\n",
    "    \n",
    "    # 3. Distribuci√≥n de anomal√≠as en el tiempo\n",
    "    ax3 = axes[1, 0]\n",
    "    if 'anomalia' in df_anomalias.columns:\n",
    "        # Crear serie temporal de anomal√≠as\n",
    "        df_time_anomalies = df_anomalias.copy()\n",
    "        if hasattr(df_time_anomalies.index, 'date'):\n",
    "            # Resamplear por d√≠a para ver patrones\n",
    "            daily_anomalies = df_time_anomalies['anomalia'].resample('D').sum()\n",
    "            \n",
    "            ax3.plot(daily_anomalies.index, daily_anomalies.values, 'r-', alpha=0.7, linewidth=2)\n",
    "            ax3.fill_between(daily_anomalies.index, daily_anomalies.values, alpha=0.3, color='red')\n",
    "            ax3.set_title('üìÖ Anomal√≠as Detectadas por D√≠a')\n",
    "            ax3.set_xlabel('Fecha')\n",
    "            ax3.set_ylabel('N√∫mero de Anomal√≠as')\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            # Gr√°fico de barras simple si no hay √≠ndice temporal\n",
    "            anomalias_count = df_anomalias['anomalia'].value_counts()\n",
    "            ax3.bar(['Normal', 'Anomal√≠a'], [anomalias_count.get(0, 0), anomalias_count.get(1, 0)], \n",
    "                   color=['green', 'red'], alpha=0.7)\n",
    "            ax3.set_title('üìä Distribuci√≥n de Anomal√≠as')\n",
    "            ax3.set_ylabel('Cantidad')\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'Anomal√≠as no disponibles', transform=ax3.transAxes, \n",
    "                ha='center', va='center', fontsize=14)\n",
    "        ax3.set_title('üìÖ Anomal√≠as - No Disponible')\n",
    "    \n",
    "    # 4. Estad√≠sticas del dataset\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    # Mostrar estad√≠sticas b√°sicas del dataset\n",
    "    numeric_cols = df_anomalias.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    if len(numeric_cols) > 0:\n",
    "        # Tomar las primeras 10 columnas para no saturar el gr√°fico\n",
    "        cols_to_plot = numeric_cols[:10]\n",
    "        means = [df_anomalias[col].mean() for col in cols_to_plot]\n",
    "        stds = [df_anomalias[col].std() for col in cols_to_plot]\n",
    "        \n",
    "        x = np.arange(len(cols_to_plot))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Normalizar para visualizaci√≥n\n",
    "        max_mean = max(means) if means else 1\n",
    "        max_std = max(stds) if stds else 1\n",
    "        means_norm = [m/max_mean for m in means]\n",
    "        stds_norm = [s/max_std for s in stds]\n",
    "        \n",
    "        ax4.bar(x - width/2, means_norm, width, label='Media (norm)', alpha=0.7, color='blue')\n",
    "        ax4.bar(x + width/2, stds_norm, width, label='Desv. Est√°ndar (norm)', alpha=0.7, color='orange')\n",
    "        \n",
    "        ax4.set_title('üìà Estad√≠sticas de Caracter√≠sticas Principales')\n",
    "        ax4.set_ylabel('Valor Normalizado')\n",
    "        ax4.set_xticks(x)\n",
    "        ax4.set_xticklabels([col[:15] + '...' if len(col) > 15 else col for col in cols_to_plot], \n",
    "                            rotation=45, ha='right')\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3, axis='y')\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'No hay columnas num√©ricas', transform=ax4.transAxes, \n",
    "                ha='center', va='center', fontsize=14)\n",
    "        ax4.set_title('üìà Estad√≠sticas - No Disponible')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Crear visualizaciones\n",
    "try:\n",
    "    visualizaciones_integradas(df_con_caracteristicas, resultados_ml, resultados_prophet, resultados_evaluacion)\n",
    "    print(\"‚úÖ Visualizaciones generadas exitosamente\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error en visualizaciones: {e}\")\n",
    "    print(\"Creando visualizaci√≥n b√°sica...\")\n",
    "    \n",
    "    # Visualizaci√≥n b√°sica de respaldo\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    if 'anomalia' in df_con_caracteristicas.columns:\n",
    "        anomalias_count = df_con_caracteristicas['anomalia'].value_counts()\n",
    "        plt.bar(['Normal', 'Anomal√≠a'], [anomalias_count.get(0, 0), anomalias_count.get(1, 0)], \n",
    "               color=['green', 'red'], alpha=0.7)\n",
    "        plt.title('üìä Distribuci√≥n de Anomal√≠as Detectadas')\n",
    "        plt.ylabel('Cantidad')\n",
    "        \n",
    "        # Agregar valores en las barras\n",
    "        for i, v in enumerate([anomalias_count.get(0, 0), anomalias_count.get(1, 0)]):\n",
    "            plt.text(i, v + max(anomalias_count.values) * 0.01, str(v), ha='center', va='bottom')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No hay datos de anomal√≠as disponibles', transform=plt.gca().transAxes, \n",
    "                ha='center', va='center', fontsize=14)\n",
    "        plt.title('üìä Estado del Sistema')\n",
    "    \n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 9: REPORTE INTEGRADO FINAL\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nüìã GENERANDO REPORTE INTEGRADO FINAL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def generar_reporte_integrado(df_caracteristicas, resultados_ml, resultados_prophet, resultados_eval):\n",
    "    \"\"\"Generar reporte que combina todos los an√°lisis\"\"\"\n",
    "    \n",
    "    reporte = {\n",
    "        'timestamp': pd.Timestamp.now(),\n",
    "        'sistema': {\n",
    "            'modulos_integrados': modulos_disponibles,\n",
    "            'prophet_disponible': prophet_disponible,\n",
    "            'caracteristicas_avanzadas': caracteristicas_creadas,\n",
    "            'ml_ejecutado': ml_exitoso if 'ml_exitoso' in locals() else False\n",
    "        },\n",
    "        'datos': {\n",
    "            'registros_totales': len(df_caracteristicas),\n",
    "            'caracteristicas_totales': len(df_caracteristicas.columns),\n",
    "            'anomalias_detectadas': df_caracteristicas.get('anomalia', pd.Series([0])).sum(),\n",
    "            'periodo_analizado': {\n",
    "                'inicio': df_caracteristicas.index.min() if hasattr(df_caracteristicas.index, 'min') else 'N/A',\n",
    "                'fin': df_caracteristicas.index.max() if hasattr(df_caracteristicas.index, 'max') else 'N/A'\n",
    "            }\n",
    "        },\n",
    "        'ml_results': {},\n",
    "        'prophet_results': {},\n",
    "        'conclusiones': []\n",
    "    }\n",
    "    \n",
    "    # Resultados de ML\n",
    "    if resultados_eval and len(resultados_eval) > 0:\n",
    "        mejor_modelo = max(resultados_eval.keys(), \n",
    "                          key=lambda x: resultados_eval[x]['f1'])\n",
    "        reporte['ml_results'] = {\n",
    "            'mejor_modelo': mejor_modelo,\n",
    "            'mejor_f1_score': resultados_eval[mejor_modelo]['f1'],\n",
    "            'modelos_evaluados': len(resultados_eval),\n",
    "            'todos_los_modelos': {\n",
    "                modelo: {\n",
    "                    'f1': res['f1'],\n",
    "                    'precision': res['precision'],\n",
    "                    'recall': res['recall']\n",
    "                } for modelo, res in resultados_eval.items()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        reporte['conclusiones'].append(\n",
    "            f\"‚úÖ Mejor modelo ML: {mejor_modelo} (F1: {resultados_eval[mejor_modelo]['f1']:.3f})\"\n",
    "        )\n",
    "    else:\n",
    "        reporte['conclusiones'].append(\"‚ö†Ô∏è Modelos ML no evaluados\")\n",
    "    \n",
    "    # Resultados de Prophet\n",
    "    if resultados_prophet:\n",
    "        reporte['prophet_results'] = {\n",
    "            'mae': resultados_prophet['metrics']['mae'],\n",
    "            'rmse': resultados_prophet['metrics']['rmse'],\n",
    "            'smape': resultados_prophet['metrics']['smape'],\n",
    "            'predicciones_futuras': len(resultados_prophet['forecast']) - len(resultados_prophet['data_used']),\n",
    "            'datos_entrenamiento': len(resultados_prophet['data_used'])\n",
    "        }\n",
    "        \n",
    "        calidad_prophet = \"Excelente\" if resultados_prophet['metrics']['smape'] < 10 else \\\n",
    "                         \"Buena\" if resultados_prophet['metrics']['smape'] < 20 else \"Regular\"\n",
    "        \n",
    "        reporte['conclusiones'].append(\n",
    "            f\"‚úÖ Prophet SMAPE: {resultados_prophet['metrics']['smape']:.1f}% ({calidad_prophet})\"\n",
    "        )\n",
    "    else:\n",
    "        reporte['conclusiones'].append(\"‚ö†Ô∏è An√°lisis Prophet no completado\")\n",
    "    \n",
    "    # An√°lisis de anomal√≠as\n",
    "    if 'anomalia' in df_caracteristicas.columns:\n",
    "        anomalias = df_caracteristicas['anomalia']\n",
    "        total_anomalias = anomalias.sum()\n",
    "        porcentaje_anomalias = (total_anomalias / len(anomalias)) * 100\n",
    "        \n",
    "        reporte['conclusiones'].extend([\n",
    "            f\"üìä Anomal√≠as detectadas: {total_anomalias} ({porcentaje_anomalias:.2f}%)\",\n",
    "        ])\n",
    "        \n",
    "        if porcentaje_anomalias < 1:\n",
    "            reporte['conclusiones'].append(\"‚úÖ Sistema operando dentro de par√°metros normales\")\n",
    "        elif porcentaje_anomalias < 5:\n",
    "            reporte['conclusiones'].append(\"‚ö†Ô∏è Algunas anomal√≠as detectadas - Monitoreo recomendado\")\n",
    "        else:\n",
    "            reporte['conclusiones'].append(\"üö® Alto n√∫mero de anomal√≠as - Intervenci√≥n requerida\")\n",
    "    \n",
    "    # Estado del sistema integrado\n",
    "    if modulos_disponibles and caracteristicas_creadas:\n",
    "        reporte['conclusiones'].append(\"üöÄ Sistema integrado funcionando correctamente\")\n",
    "        reporte['conclusiones'].append(\"‚úÖ Listo para despliegue en producci√≥n\")\n",
    "    else:\n",
    "        reporte['conclusiones'].append(\"‚ö†Ô∏è Sistema funcionando en modo b√°sico\")\n",
    "    \n",
    "    return reporte\n",
    "\n",
    "# Generar reporte final\n",
    "reporte_final = generar_reporte_integrado(\n",
    "    df_con_caracteristicas, \n",
    "    resultados_ml, \n",
    "    resultados_prophet, \n",
    "    resultados_evaluacion if 'resultados_evaluacion' in locals() else None\n",
    ")\n",
    "\n",
    "# Mostrar reporte\n",
    "print(\"üèÜ REPORTE INTEGRADO COMPLETADO\")\n",
    "print(\"=\"*40)\n",
    "print(f\"üìÖ Generado: {reporte_final['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nüîß ESTADO DEL SISTEMA:\")\n",
    "print(f\"   - M√≥dulos integrados: {'‚úÖ' if reporte_final['sistema']['modulos_integrados'] else '‚ùå'}\")\n",
    "print(f\"   - Prophet disponible: {'‚úÖ' if reporte_final['sistema']['prophet_disponible'] else '‚ùå'}\")\n",
    "print(f\"   - Caracter√≠sticas avanzadas: {'‚úÖ' if reporte_final['sistema']['caracteristicas_avanzadas'] else '‚ùå'}\")\n",
    "print(f\"   - ML ejecutado: {'‚úÖ' if reporte_final['sistema']['ml_ejecutado'] else '‚ùå'}\")\n",
    "\n",
    "print(f\"\\nüìä DATOS PROCESADOS:\")\n",
    "print(f\"   - Registros: {reporte_final['datos']['registros_totales']:,}\")\n",
    "print(f\"   - Caracter√≠sticas: {reporte_final['datos']['caracteristicas_totales']}\")\n",
    "print(f\"   - Anomal√≠as: {reporte_final['datos']['anomalias_detectadas']}\")\n",
    "\n",
    "if reporte_final['ml_results']:\n",
    "    print(f\"\\nü§ñ RESULTADOS ML:\")\n",
    "    print(f\"   - Mejor modelo: {reporte_final['ml_results']['mejor_modelo']}\")\n",
    "    print(f\"   - F1-Score: {reporte_final['ml_results']['mejor_f1_score']:.3f}\")\n",
    "    print(f\"   - Modelos evaluados: {reporte_final['ml_results']['modelos_evaluados']}\")\n",
    "\n",
    "if reporte_final['prophet_results']:\n",
    "    print(f\"\\nüîÆ RESULTADOS PROPHET:\")\n",
    "    print(f\"   - SMAPE: {reporte_final['prophet_results']['smape']:.2f}%\")\n",
    "    print(f\"   - MAE: {reporte_final['prophet_results']['mae']:.2f}\")\n",
    "    print(f\"   - Predicciones futuras: {reporte_final['prophet_results']['predicciones_futuras']}\")\n",
    "\n",
    "print(f\"\\nüí° CONCLUSIONES:\")\n",
    "for i, conclusion in enumerate(reporte_final['conclusiones'], 1):\n",
    "    print(f\"   {i}. {conclusion}\")\n",
    "\n",
    "# Calcular score general del sistema\n",
    "score_sistema = 0\n",
    "if reporte_final['sistema']['modulos_integrados']: score_sistema += 25\n",
    "if reporte_final['sistema']['prophet_disponible']: score_sistema += 25\n",
    "if reporte_final['sistema']['caracteristicas_avanzadas']: score_sistema += 25\n",
    "if reporte_final['sistema']['ml_ejecutado']: score_sistema += 25\n",
    "\n",
    "print(f\"\\nüéØ SCORE GENERAL DEL SISTEMA: {score_sistema}/100\")\n",
    "if score_sistema >= 75:\n",
    "    print(\"   Estado: üü¢ EXCELENTE - Sistema completamente funcional\")\n",
    "elif score_sistema >= 50:\n",
    "    print(\"   Estado: üü° BUENO - Sistema funcional con limitaciones\")\n",
    "else:\n",
    "    print(\"   Estado: üî¥ B√ÅSICO - Sistema funcionando en modo limitado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 10: GUARDAR RESULTADOS\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nüíæ GUARDANDO RESULTADOS INTEGRADOS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "archivos_guardados = []\n",
    "\n",
    "try:\n",
    "    # Guardar dataset con caracter√≠sticas\n",
    "    archivo_principal = 'anomalias_detectadas_INTEGRADO.csv'\n",
    "    df_con_caracteristicas.to_csv(archivo_principal)\n",
    "    archivos_guardados.append(archivo_principal)\n",
    "    print(f\"‚úì Dataset principal guardado: {archivo_principal}\")\n",
    "    print(f\"   - Registros: {len(df_con_caracteristicas):,}\")\n",
    "    print(f\"   - Columnas: {len(df_con_caracteristicas.columns)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error guardando dataset principal: {e}\")\n",
    "\n",
    "try:\n",
    "    # Guardar reporte en JSON\n",
    "    import json\n",
    "    \n",
    "    # Convertir timestamps para JSON\n",
    "    reporte_json = reporte_final.copy()\n",
    "    reporte_json['timestamp'] = reporte_final['timestamp'].isoformat()\n",
    "    \n",
    "    if isinstance(reporte_json['datos']['periodo_analizado']['inicio'], pd.Timestamp):\n",
    "        reporte_json['datos']['periodo_analizado']['inicio'] = reporte_final['datos']['periodo_analizado']['inicio'].isoformat()\n",
    "    if isinstance(reporte_json['datos']['periodo_analizado']['fin'], pd.Timestamp):\n",
    "        reporte_json['datos']['periodo_analizado']['fin'] = reporte_final['datos']['periodo_analizado']['fin'].isoformat()\n",
    "    \n",
    "    archivo_reporte = 'reporte_integrado.json'\n",
    "    with open(archivo_reporte, 'w', encoding='utf-8') as f:\n",
    "        json.dump(reporte_json, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    archivos_guardados.append(archivo_reporte)\n",
    "    print(f\"‚úì Reporte JSON guardado: {archivo_reporte}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error guardando reporte JSON: {e}\")\n",
    "\n",
    "try:\n",
    "    # Guardar predicciones Prophet si existen\n",
    "    if resultados_prophet:\n",
    "        archivo_prophet = 'predicciones_prophet_integrado.csv'\n",
    "        resultados_prophet['forecast'].to_csv(archivo_prophet, index=False)\n",
    "        archivos_guardados.append(archivo_prophet)\n",
    "        print(f\"‚úì Predicciones Prophet guardadas: {archivo_prophet}\")\n",
    "        print(f\"   - Predicciones: {len(resultados_prophet['forecast'])}\")\n",
    "        print(f\"   - SMAPE: {resultados_prophet['metrics']['smape']:.2f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error guardando predicciones Prophet: {e}\")\n",
    "\n",
    "try:\n",
    "    # Guardar resultados ML si existen\n",
    "    if 'resultados_evaluacion' in locals() and resultados_evaluacion:\n",
    "        # Crear DataFrame con resultados ML\n",
    "        ml_results_df = pd.DataFrame({\n",
    "            'modelo': list(resultados_evaluacion.keys()),\n",
    "            'f1_score': [res['f1'] for res in resultados_evaluacion.values()],\n",
    "            'precision': [res['precision'] for res in resultados_evaluacion.values()],\n",
    "            'recall': [res['recall'] for res in resultados_evaluacion.values()],\n",
    "            'accuracy': [res['accuracy'] for res in resultados_evaluacion.values()]\n",
    "        })\n",
    "        \n",
    "        archivo_ml = 'resultados_ml_integrado.csv'\n",
    "        ml_results_df.to_csv(archivo_ml, index=False)\n",
    "        archivos_guardados.append(archivo_ml)\n",
    "        print(f\"‚úì Resultados ML guardados: {archivo_ml}\")\n",
    "        print(f\"   - Modelos evaluados: {len(ml_results_df)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error guardando resultados ML: {e}\")\n",
    "\n",
    "# Crear archivo de resumen\n",
    "try:\n",
    "    archivo_resumen = 'RESUMEN_EJECUCION.txt'\n",
    "    with open(archivo_resumen, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"üîã RESUMEN DE EJECUCI√ìN - SISTEMA INTEGRADO\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        f.write(f\"Fecha de ejecuci√≥n: {reporte_final['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Score del sistema: {score_sistema}/100\\n\\n\")\n",
    "        \n",
    "        f.write(\"üìÅ ARCHIVOS GENERADOS:\\n\")\n",
    "        for i, archivo in enumerate(archivos_guardados, 1):\n",
    "            f.write(f\"   {i}. {archivo}\\n\")\n",
    "        \n",
    "        f.write(\"\\nüí° CONCLUSIONES:\\n\")\n",
    "        for i, conclusion in enumerate(reporte_final['conclusiones'], 1):\n",
    "            f.write(f\"   {i}. {conclusion}\\n\")\n",
    "        \n",
    "        f.write(\"\\nüîß CONFIGURACI√ìN:\\n\")\n",
    "        f.write(f\"   - M√≥dulos integrados: {reporte_final['sistema']['modulos_integrados']}\\n\")\n",
    "        f.write(f\"   - Prophet disponible: {reporte_final['sistema']['prophet_disponible']}\\n\")\n",
    "        f.write(f\"   - Caracter√≠sticas avanzadas: {reporte_final['sistema']['caracteristicas_avanzadas']}\\n\")\n",
    "        f.write(f\"   - ML ejecutado: {reporte_final['sistema']['ml_ejecutado']}\\n\")\n",
    "    \n",
    "    archivos_guardados.append(archivo_resumen)\n",
    "    print(f\"‚úì Resumen guardado: {archivo_resumen}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error guardando resumen: {e}\")\n",
    "\n",
    "print(f\"\\nüìÇ ARCHIVOS GENERADOS TOTAL: {len(archivos_guardados)}\")\n",
    "for i, archivo in enumerate(archivos_guardados, 1):\n",
    "    print(f\"   {i}. {archivo}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Proceso de guardado completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 11: SISTEMA DE ALERTAS FINAL\n",
    "# ========================================\n",
    "\n",
    "def sistema_alertas_integrado(df_anomalias, resultados_prophet, umbral_critico=0.95):\n",
    "    \"\"\"Sistema de alertas que integra todos los m√©todos\"\"\"\n",
    "    print(\"\\nüö® SISTEMA DE ALERTAS INTEGRADO\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    alertas_activas = []\n",
    "    \n",
    "    # 1. Verificar anomal√≠as recientes\n",
    "    if 'anomalia' in df_anomalias.columns:\n",
    "        total_anomalias = df_anomalias['anomalia'].sum()\n",
    "        porcentaje_anomalias = (total_anomalias / len(df_anomalias)) * 100\n",
    "        \n",
    "        # Alerta por alta frecuencia de anomal√≠as\n",
    "        if porcentaje_anomalias > 10:\n",
    "            alertas_activas.append({\n",
    "                'tipo': 'ALTA_FRECUENCIA_ANOMALIAS',\n",
    "                'severidad': 'CR√çTICA',\n",
    "                'mensaje': f'{total_anomalias} anomal√≠as detectadas ({porcentaje_anomalias:.1f}%)',\n",
    "                'accion_recomendada': 'Inspecci√≥n t√©cnica inmediata del sistema'\n",
    "            })\n",
    "        elif porcentaje_anomalias > 5:\n",
    "            alertas_activas.append({\n",
    "                'tipo': 'FRECUENCIA_ANOMALIAS_ELEVADA',\n",
    "                'severidad': 'ALTA',\n",
    "                'mensaje': f'{total_anomalias} anomal√≠as detectadas ({porcentaje_anomalias:.1f}%)',\n",
    "                'accion_recomendada': 'Revisi√≥n t√©cnica programada'\n",
    "            })\n",
    "        elif porcentaje_anomalias > 1:\n",
    "            alertas_activas.append({\n",
    "                'tipo': 'ANOMALIAS_DETECTADAS',\n",
    "                'severidad': 'MEDIA',\n",
    "                'mensaje': f'{total_anomalias} anomal√≠as detectadas ({porcentaje_anomalias:.1f}%)',\n",
    "                'accion_recomendada': 'Monitoreo continuo recomendado'\n",
    "            })\n",
    "    \n",
    "    # 2. Verificar tendencias Prophet (si disponible)\n",
    "    if resultados_prophet:\n",
    "        forecast = resultados_prophet['forecast']\n",
    "        \n",
    "        # An√°lisis de tendencia en predicciones\n",
    "        if len(forecast) > 30:\n",
    "            tendencia_reciente = forecast['trend'].tail(30).pct_change().mean()\n",
    "            \n",
    "            if tendencia_reciente < -0.10:  # Tendencia negativa > 10%\n",
    "                alertas_activas.append({\n",
    "                    'tipo': 'TENDENCIA_NEGATIVA_CRITICA',\n",
    "                    'severidad': 'ALTA',\n",
    "                    'mensaje': f'Tendencia de producci√≥n muy negativa: {tendencia_reciente:.2%}',\n",
    "                    'accion_recomendada': 'Revisi√≥n urgente del sistema y mantenimiento'\n",
    "                })\n",
    "            elif tendencia_reciente < -0.05:  # Tendencia negativa > 5%\n",
    "                alertas_activas.append({\n",
    "                    'tipo': 'TENDENCIA_NEGATIVA',\n",
    "                    'severidad': 'MEDIA',\n",
    "                    'mensaje': f'Tendencia de producci√≥n negativa: {tendencia_reciente:.2%}',\n",
    "                    'accion_recomendada': 'Revisi√≥n de mantenimiento preventivo'\n",
    "                })\n",
    "        \n",
    "        # Verificar calidad del modelo Prophet\n",
    "        smape = resultados_prophet['metrics']['smape']\n",
    "        if smape > 25:\n",
    "            alertas_activas.append({\n",
    "                'tipo': 'MODELO_PREDICTIVO_DEGRADADO',\n",
    "                'severidad': 'MEDIA',\n",
    "                'mensaje': f'Calidad del modelo predictivo baja (SMAPE: {smape:.1f}%)',\n",
    "                'accion_recomendada': 'Reentrenamiento del modelo recomendado'\n",
    "            })\n",
    "    \n",
    "    # 3. Verificar estado de integraci√≥n del sistema\n",
    "    if not modulos_disponibles:\n",
    "        alertas_activas.append({\n",
    "            'tipo': 'SISTEMA_MODO_BASICO',\n",
    "            'severidad': 'BAJA',\n",
    "            'mensaje': 'Sistema funcionando en modo b√°sico (m√≥dulos no disponibles)',\n",
    "            'accion_recomendada': 'Verificar instalaci√≥n de m√≥dulos propios'\n",
    "        })\n",
    "    \n",
    "    if not prophet_disponible:\n",
    "        alertas_activas.append({\n",
    "            'tipo': 'PREDICCIONES_NO_DISPONIBLES',\n",
    "            'severidad': 'BAJA',\n",
    "            'mensaje': 'An√°lisis predictivo no disponible (Prophet no instalado)',\n",
    "            'accion_recomendada': 'Instalar Prophet para an√°lisis predictivo completo'\n",
    "        })\n",
    "    \n",
    "    # 4. Mostrar alertas\n",
    "    if alertas_activas:\n",
    "        print(f\"‚ö†Ô∏è {len(alertas_activas)} ALERTAS ACTIVAS:\")\n",
    "        print()\n",
    "        \n",
    "        # Agrupar por severidad\n",
    "        alertas_por_severidad = {}\n",
    "        for alerta in alertas_activas:\n",
    "            sev = alerta['severidad']\n",
    "            if sev not in alertas_por_severidad:\n",
    "                alertas_por_severidad[sev] = []\n",
    "            alertas_por_severidad[sev].append(alerta)\n",
    "        \n",
    "        # Mostrar por orden de severidad\n",
    "        orden_severidad = ['CR√çTICA', 'ALTA', 'MEDIA', 'BAJA']\n",
    "        for severidad in orden_severidad:\n",
    "            if severidad in alertas_por_severidad:\n",
    "                icon = {'CR√çTICA': 'üî¥', 'ALTA': 'üü†', 'MEDIA': 'üü°', 'BAJA': 'üîµ'}[severidad]\n",
    "                print(f\"{icon} SEVERIDAD {severidad}:\")\n",
    "                \n",
    "                for i, alerta in enumerate(alertas_por_severidad[severidad], 1):\n",
    "                    print(f\"   {i}. {alerta['tipo']}\")\n",
    "                    print(f\"      {alerta['mensaje']}\")\n",
    "                    print(f\"      Acci√≥n: {alerta['accion_recomendada']}\")\n",
    "                    print()\n",
    "    else:\n",
    "        print(\"‚úÖ No hay alertas activas\")\n",
    "        print(\"   Sistema operando normalmente\")\n",
    "    \n",
    "    # 5. Recomendaciones generales\n",
    "    print(\"\\nüí° RECOMENDACIONES GENERALES:\")\n",
    "    \n",
    "    if score_sistema >= 75:\n",
    "        print(\"   ‚úÖ Sistema funcionando √≥ptimamente\")\n",
    "        print(\"   ‚úÖ Listo para despliegue en producci√≥n\")\n",
    "        print(\"   ‚úÖ Monitoreo autom√°tico recomendado\")\n",
    "    elif score_sistema >= 50:\n",
    "        print(\"   üü° Sistema funcional con mejoras posibles\")\n",
    "        print(\"   üü° Considerar actualizaci√≥n de m√≥dulos\")\n",
    "        print(\"   üü° Monitoreo manual recomendado\")\n",
    "    else:\n",
    "        print(\"   üî¥ Sistema necesita mejoras\")\n",
    "        print(\"   üî¥ Instalar m√≥dulos faltantes\")\n",
    "        print(\"   üî¥ Supervisi√≥n t√©cnica requerida\")\n",
    "    \n",
    "    return alertas_activas\n",
    "\n",
    "# Ejecutar sistema de alertas\n",
    "alertas = sistema_alertas_integrado(df_con_caracteristicas, resultados_prophet)\n",
    "\n",
    "print(f\"\\nüèÅ SISTEMA INTEGRADO COMPLETADO\")\n",
    "print(f\"=\"*50)\n",
    "print(f\"‚úÖ Notebook ejecutado: 11 celdas\")\n",
    "print(f\"‚úÖ M√≥dulos integrados: {'S√≠' if modulos_disponibles else 'No'}\")\n",
    "print(f\"‚úÖ An√°lisis ML: {'S√≠' if 'ml_exitoso' in locals() and ml_exitoso else 'No'}\")\n",
    "print(f\"‚úÖ An√°lisis Prophet: {'S√≠' if resultados_prophet else 'No'}\")\n",
    "print(f\"‚úÖ Sistema de alertas: {len(alertas)} alertas activas\")\n",
    "print(f\"‚úÖ Archivos guardados: {len(archivos_guardados)}\")\n",
    "print(f\"\\nüéØ Score final del sistema: {score_sistema}/100\")\n",
    "print(f\"\\nüöÄ ¬°Sistema integrado listo para usar!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
